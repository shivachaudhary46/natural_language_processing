{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "uQxnKG5kxaIy",
        "outputId": "9f84aebb-285b-4ab9-b069-285538d252ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"first create dictionary full of vocabulary. then calculate your text co-occurence and \\norder by descending. so highest repeating word come at first. \\nthen if that text's word matches with the GloVe file.\\nIn GloVe file there is dimension file which we have already downloaded. \\nselect one of dimension. if the text's word matches \\nwith GloVe file word then copy vector of GloVe file and paste into Embedding matrix create for users\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Glove is Pre trained model which is works by using calculating\n",
        "# co-occurence of word with they appear together in a given context.\n",
        "'''first create dictionary full of vocabulary. then calculate your text co-occurence and\n",
        "order by descending. so highest repeating word come at first.\n",
        "then if that text's word matches with the GloVe file.\n",
        "In GloVe file there is dimension file which we have already downloaded.\n",
        "select one of dimension. if the text's word matches\n",
        "with GloVe file word then copy vector of GloVe file and paste into Embedding matrix create for users'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "FHIqyp_h3KRd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = '''The creation of a word co-occurrence matrix is the fundamental component of GloVe.\n",
        "This matrix provides a quantitative measure of the semantic affinity between words by capturing\n",
        "the frequency with which they appear together in a given context. Further, by minimising the\n",
        "difference between the dot product of vectors and the pointwise mutual information of corresponding\n",
        "words, GloVe optimises word vectors. It is able to produce dense vector representations that capture\n",
        "syntactic and semantic relationships'''\n"
      ],
      "metadata": {
        "id": "RZmddCho3oaa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = corpus.split(' ')\n",
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXFIh2494iTx",
        "outputId": "3e52bdcf-2fdc-4c6f-8a73-79d68ff6b639"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'creation',\n",
              " 'of',\n",
              " 'a',\n",
              " 'word',\n",
              " 'co-occurrence',\n",
              " 'matrix',\n",
              " 'is',\n",
              " 'the',\n",
              " 'fundamental',\n",
              " 'component',\n",
              " 'of',\n",
              " 'GloVe.',\n",
              " '\\nThis',\n",
              " 'matrix',\n",
              " 'provides',\n",
              " 'a',\n",
              " 'quantitative',\n",
              " 'measure',\n",
              " 'of',\n",
              " 'the',\n",
              " 'semantic',\n",
              " 'affinity',\n",
              " 'between',\n",
              " 'words',\n",
              " 'by',\n",
              " 'capturing',\n",
              " '\\nthe',\n",
              " 'frequency',\n",
              " 'with',\n",
              " 'which',\n",
              " 'they',\n",
              " 'appear',\n",
              " 'together',\n",
              " 'in',\n",
              " 'a',\n",
              " 'given',\n",
              " 'context.',\n",
              " 'Further,',\n",
              " 'by',\n",
              " 'minimising',\n",
              " 'the',\n",
              " '\\ndifference',\n",
              " 'between',\n",
              " 'the',\n",
              " 'dot',\n",
              " 'product',\n",
              " 'of',\n",
              " 'vectors',\n",
              " 'and',\n",
              " 'the',\n",
              " 'pointwise',\n",
              " 'mutual',\n",
              " 'information',\n",
              " 'of',\n",
              " 'corresponding',\n",
              " '\\nwords,',\n",
              " 'GloVe',\n",
              " 'optimises',\n",
              " 'word',\n",
              " 'vectors.',\n",
              " 'It',\n",
              " 'is',\n",
              " 'able',\n",
              " 'to',\n",
              " 'produce',\n",
              " 'dense',\n",
              " 'vector',\n",
              " 'representations',\n",
              " 'that',\n",
              " 'capture',\n",
              " '\\nsyntactic',\n",
              " 'and',\n",
              " 'semantic',\n",
              " 'relationships']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and fit the tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "print(\"len of dictionary:\", len(tokenizer.word_index))\n",
        "print('dictionary:', tokenizer.word_index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw5DIRJB4sJT",
        "outputId": "26038965-88c5-45bb-a6f9-ae14b9ac15b6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len of dictionary: 54\n",
            "dictionary: {'the': 1, 'of': 2, 'a': 3, 'word': 4, 'matrix': 5, 'is': 6, 'glove': 7, 'semantic': 8, 'between': 9, 'words': 10, 'by': 11, 'vectors': 12, 'and': 13, 'creation': 14, 'co': 15, 'occurrence': 16, 'fundamental': 17, 'component': 18, 'this': 19, 'provides': 20, 'quantitative': 21, 'measure': 22, 'affinity': 23, 'capturing': 24, 'frequency': 25, 'with': 26, 'which': 27, 'they': 28, 'appear': 29, 'together': 30, 'in': 31, 'given': 32, 'context': 33, 'further': 34, 'minimising': 35, 'difference': 36, 'dot': 37, 'product': 38, 'pointwise': 39, 'mutual': 40, 'information': 41, 'corresponding': 42, 'optimises': 43, 'it': 44, 'able': 45, 'to': 46, 'produce': 47, 'dense': 48, 'vector': 49, 'representations': 50, 'that': 51, 'capture': 52, 'syntactic': 53, 'relationships': 54}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def embedding_vector(file_path, word_index, embedding_dim):\n",
        "  vocab_size = len(word_index) + 1 # padding word_index with 1\n",
        "  embedding_matrix_vocab = np.zeros((vocab_size, embedding_dim))\n",
        "  with open(file_path, encoding='utf8') as files:\n",
        "    for file in files:\n",
        "      word, *vector = file.split()\n",
        "      if word in word_index:\n",
        "        idx = word_index[word]\n",
        "        embedding_matrix_vocab[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]\n",
        "\n",
        "  return embedding_matrix_vocab"
      ],
      "metadata": {
        "id": "jtzCV25U6-Np"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the GloVe dataset\n",
        "!wget https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
        "\n",
        "# Unzip the file\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWvinT7r-Pjd",
        "outputId": "1fe7f3f6-d494-4c4f-e180-2fddb5abbab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-01 04:59:46--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1      100%[===================>] 822.24M  5.14MB/s    in 2m 40s  \n",
            "\n",
            "2025-08-01 05:02:26 (5.15 MB/s) - ‘glove.6B.zip.1’ saved [862182613/862182613]\n",
            "\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 50\n",
        "glove_path = './glove.6B.50d.txt'\n",
        "\n",
        "embedding_matrix_vocab = embedding_vector(glove_path, tokenizer.word_index, embedding_dim)"
      ],
      "metadata": {
        "id": "PAI90pV0-SLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_word_index = 1\n",
        "print(embedding_matrix_vocab[first_word_index])"
      ],
      "metadata": {
        "id": "cz3MYdgK_G3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "upIGVUJQ_VU2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}