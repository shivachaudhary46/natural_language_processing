{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Algorithm to see how WordPiece Tokenization works\n",
        "The algorithm follows a data driven approach to build its vocaulary. it starts with individual characters and gradually merges the most frequently occuring pairs until reaching a target a vocaulary size.\n",
        "\n",
        "- Take input text.\n",
        "- convert text into bigrams chars\n",
        "- calculate the unique co-occurency of each bigrams count.\n",
        "- Pick a consecutive pair that has highest joint probability\n",
        "  - p(c1, c2) = count(c1, c2) / count(1) * count(2)\n",
        "- treat previously picked pair as single token and add to vocabulary\n",
        "- pick a consecutive pair which have highest number of co occurency\n",
        "- treat previously picked pair as a single token and add to vocabulary. and repeat step 6"
      ],
      "metadata": {
        "id": "LEc56Vty_HJr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmdGLdHOw4SB",
        "outputId": "fea23a12-2be5-4392-b97e-f14b746858dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['h', 'u', 'g', 's', 'p', 'u', 'g', 'b', 'u', 'n', 'b', 'u', 'n', 'p', 'u', 'g', 'h', 'u', 'g', 's', 'c', 'h', 'u', 'n', 'k', 's', 'c', 'h', 'u', 'g', 's', 'r', 'u', 'g', 's']\n"
          ]
        }
      ],
      "source": [
        "# step 1 : take input text\n",
        "example_input = \"hugs pug bun bun pug hugs chunks chugs rugs\"\n",
        "example_input = list(example_input)\n",
        "new_example = [ i for i in example_input if i != \" \"]\n",
        "print(new_example)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_ngrams(text, n):\n",
        "    tokens = text\n",
        "    ngrams = [tuple(tokens[i:i + n]) for i in range(len(tokens) - n + 1)]\n",
        "    return ngrams\n",
        "\n",
        "bigrams = generate_ngrams(new_example, 2)\n",
        "\n",
        "print(\"Bigrams:\", bigrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4XrwgNrDjid",
        "outputId": "354cbcc8-90c5-4edb-d069-17c21e7f53ca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigrams: [('h', 'u'), ('u', 'g'), ('g', 's'), ('s', 'p'), ('p', 'u'), ('u', 'g'), ('g', 'b'), ('b', 'u'), ('u', 'n'), ('n', 'b'), ('b', 'u'), ('u', 'n'), ('n', 'p'), ('p', 'u'), ('u', 'g'), ('g', 'h'), ('h', 'u'), ('u', 'g'), ('g', 's'), ('s', 'c'), ('c', 'h'), ('h', 'u'), ('u', 'n'), ('n', 'k'), ('k', 's'), ('s', 'c'), ('c', 'h'), ('h', 'u'), ('u', 'g'), ('g', 's'), ('s', 'r'), ('r', 'u'), ('u', 'g'), ('g', 's')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create function to count the co-occurence matrix of biagram\n",
        "def count_coccurence(bigrams):\n",
        "\n",
        "  freq = {}\n",
        "  for each_word in bigrams:\n",
        "    if each_word in freq:\n",
        "      freq[each_word] += 1\n",
        "    else:\n",
        "      freq[each_word] = 1\n",
        "\n",
        "  return freq\n",
        "\n",
        "count_freq = count_coccurence(bigrams)\n",
        "print(count_freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtWEtaHgEv-D",
        "outputId": "eb6fde8e-272a-4d39-efe4-440bab430750"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{('h', 'u'): 4, ('u', 'g'): 6, ('g', 's'): 4, ('s', 'p'): 1, ('p', 'u'): 2, ('g', 'b'): 1, ('b', 'u'): 2, ('u', 'n'): 3, ('n', 'b'): 1, ('n', 'p'): 1, ('g', 'h'): 1, ('s', 'c'): 2, ('c', 'h'): 2, ('n', 'k'): 1, ('k', 's'): 1, ('s', 'r'): 1, ('r', 'u'): 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_each_word(new_example):\n",
        "  frq = {}\n",
        "  for i in new_example:\n",
        "    if i in frq:\n",
        "      frq[i] += 1\n",
        "    else:\n",
        "      frq[i] = 1\n",
        "  return frq\n",
        "word_freq = count_each_word(new_example)\n",
        "print(word_freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2iZeBxZ_RMU",
        "outputId": "54100637-143d-4ef8-bc49-20487457563f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'h': 4, 'u': 9, 'g': 6, 's': 5, 'p': 2, 'b': 2, 'n': 3, 'c': 2, 'k': 1, 'r': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "each_word_freq = [(word, count) for word, count in word_freq.items() ]\n",
        "each_word_freq = sorted(each_word_freq, key=lambda x: x[1], reverse=True)\n",
        "print(each_word_freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t0bg33RF6WN",
        "outputId": "30b77664-9e8b-4424-9477-3ea19b751753"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('u', 9), ('g', 6), ('s', 5), ('h', 4), ('n', 3), ('p', 2), ('b', 2), ('c', 2), ('k', 1), ('r', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_frequency = [ (word, count) for word, count in count_freq.items()]\n",
        "bigram_frequency = sorted(bigram_frequency, key = lambda x: x[1], reverse = True)\n",
        "print(bigram_frequency)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcCfO1B3KF-F",
        "outputId": "09c31ea2-82b0-49bd-9868-ec1f9ff65211"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(('u', 'g'), 6), (('h', 'u'), 4), (('g', 's'), 4), (('u', 'n'), 3), (('p', 'u'), 2), (('b', 'u'), 2), (('s', 'c'), 2), (('c', 'h'), 2), (('s', 'p'), 1), (('g', 'b'), 1), (('n', 'b'), 1), (('n', 'p'), 1), (('g', 'h'), 1), (('n', 'k'), 1), (('k', 's'), 1), (('s', 'r'), 1), (('r', 'u'), 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count(word):\n",
        "  return word_freq[word]"
      ],
      "metadata": {
        "id": "T1W7DtFnSsg6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def joint_probability(bigram_frequency, each_word_freq):\n",
        "  for i in bigram_frequency:\n",
        "    for i in range(0, 2):\n",
        "      print(each, i)\n",
        "      prob = each[1] / count(each[0][0]) * count(each[0][1])\n",
        "      print(prob)\n",
        "\n",
        "joint_probability(bigram_frequency, each_word_freq)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHO4cY2_LbDL",
        "outputId": "b20a7883-e14c-463a-819f-3c1f1d624ee3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(('u', 'g'), 6) 0\n",
            "4.0\n",
            "(('u', 'g'), 6) 1\n",
            "4.0\n",
            "(('h', 'u'), 4) 0\n",
            "9.0\n",
            "(('h', 'u'), 4) 1\n",
            "9.0\n",
            "(('g', 's'), 4) 0\n",
            "3.333333333333333\n",
            "(('g', 's'), 4) 1\n",
            "3.333333333333333\n",
            "(('u', 'n'), 3) 0\n",
            "1.0\n",
            "(('u', 'n'), 3) 1\n",
            "1.0\n",
            "(('p', 'u'), 2) 0\n",
            "9.0\n",
            "(('p', 'u'), 2) 1\n",
            "9.0\n",
            "(('b', 'u'), 2) 0\n",
            "9.0\n",
            "(('b', 'u'), 2) 1\n",
            "9.0\n",
            "(('s', 'c'), 2) 0\n",
            "0.8\n",
            "(('s', 'c'), 2) 1\n",
            "0.8\n",
            "(('c', 'h'), 2) 0\n",
            "4.0\n",
            "(('c', 'h'), 2) 1\n",
            "4.0\n",
            "(('s', 'p'), 1) 0\n",
            "0.4\n",
            "(('s', 'p'), 1) 1\n",
            "0.4\n",
            "(('g', 'b'), 1) 0\n",
            "0.3333333333333333\n",
            "(('g', 'b'), 1) 1\n",
            "0.3333333333333333\n",
            "(('n', 'b'), 1) 0\n",
            "0.6666666666666666\n",
            "(('n', 'b'), 1) 1\n",
            "0.6666666666666666\n",
            "(('n', 'p'), 1) 0\n",
            "0.6666666666666666\n",
            "(('n', 'p'), 1) 1\n",
            "0.6666666666666666\n",
            "(('g', 'h'), 1) 0\n",
            "0.6666666666666666\n",
            "(('g', 'h'), 1) 1\n",
            "0.6666666666666666\n",
            "(('n', 'k'), 1) 0\n",
            "0.3333333333333333\n",
            "(('n', 'k'), 1) 1\n",
            "0.3333333333333333\n",
            "(('k', 's'), 1) 0\n",
            "5.0\n",
            "(('k', 's'), 1) 1\n",
            "5.0\n",
            "(('s', 'r'), 1) 0\n",
            "0.2\n",
            "(('s', 'r'), 1) 1\n",
            "0.2\n",
            "(('r', 'u'), 1) 0\n",
            "9.0\n",
            "(('r', 'u'), 1) 1\n",
            "9.0\n"
          ]
        }
      ]
    }
  ]
}