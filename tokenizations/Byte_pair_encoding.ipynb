{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Subword Tokenization in NLP\n",
        "\n",
        "Traditional word tokenization creates a unique token for every distinct word from. word like 'run', 'running', 'ran'. despite their semantic relationships.same words, same technical terms, vocabulary can explode to millions of unique.\n",
        "\n",
        "Problem with the\n",
        "- memory computationally expensive\n",
        "- rare words are ignored\n",
        "- related word are completely taken as independent.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "O7COuVhSkkMi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uEbeG4J_phtL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6th4KSQ1jmeh",
        "outputId": "9d4ee2c1-e604-44e0-c652-4a41a9f44279"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['geeksforgeeks',\n",
              " 'is',\n",
              " 'a',\n",
              " 'fantastic',\n",
              " 'resource',\n",
              " 'for',\n",
              " 'geeks',\n",
              " 'who',\n",
              " 'are',\n",
              " 'looking',\n",
              " 'to',\n",
              " 'enhance',\n",
              " 'their',\n",
              " 'programming',\n",
              " 'skills',\n",
              " ',',\n",
              " 'and',\n",
              " 'if',\n",
              " 'you',\n",
              " \"'\",\n",
              " 're',\n",
              " 'a',\n",
              " 'geek',\n",
              " 'who',\n",
              " 'wants',\n",
              " 'to',\n",
              " 'become',\n",
              " 'an',\n",
              " 'expert',\n",
              " 'programmer',\n",
              " ',',\n",
              " 'then',\n",
              " 'geeksforge']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def preprocess_text(text):\n",
        "  '''\n",
        "  clean and tokenize the data and preprocessing.\n",
        "  return a list of tokens with lowecase and\n",
        "  tokenization\n",
        "  '''\n",
        "\n",
        "  text = text.lower()\n",
        "  tokens = re.findall(r'\\w+|[^\\w\\s]', text)\n",
        "  return tokens\n",
        "\n",
        "sample_text = \"\"\" GeeksforGeeks is a fantastic resource for geeks\n",
        "who are looking to enhance their programming skills,\n",
        "and if you're a geek who wants to become an expert programmer,\n",
        "then GeeksforGe\"\"\"\n",
        "\n",
        "\n",
        "preprocess_text(sample_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Byte Pair encoding implementation\n",
        "'''\n",
        "Byte pair Encoding works on iteratively merging the most frequent pairs of sy\n",
        "mbols until reaching a desired vocabulary size. This creates a balance between\n",
        "character tokenization and word level tokenization.\n",
        "\n",
        "intial_vocabulary : words are split into characters with their frequencies for eg: {'l o w e r': 2}\n",
        "lower is repeated two times in the sentences or corpus\n",
        "\n",
        "get symbol pairs : it counts how often the similar character pair appears\n",
        "\n",
        "Merge step : if the char is repeated several times then it will merge into single token\n",
        "\n",
        "BPE loop : repeats the merging most common pair for a set of times and updatinfg the vocab\n",
        "each time.\n",
        "\n",
        "Final ooutput : Prints the updated vocabulary after all merges,\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "t8UGbI431neG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# step 1: Input vocabulary ( word -> frequency)\n",
        "vocab = {\n",
        "    'l o w': 5,\n",
        "    'l o w e r': 2,\n",
        "    'n e w e s t': 6,\n",
        "    'w i d e s t': 3\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XNG8pncDAWDo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}