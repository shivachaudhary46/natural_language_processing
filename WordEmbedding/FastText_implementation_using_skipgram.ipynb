{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izuLxvSIxhbt",
        "outputId": "6142a340-82b5-46cd-8080-0ff816781ad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting FastText\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from FastText)\n",
            "  Using cached pybind11-3.0.0-py3-none-any.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from FastText) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from FastText) (2.0.2)\n",
            "Using cached pybind11-3.0.0-py3-none-any.whl (292 kB)\n",
            "Building wheels for collected packages: FastText\n",
            "  Building wheel for FastText (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for FastText: filename=fasttext-0.9.3-cp311-cp311-linux_x86_64.whl size=4508437 sha256=009c1c12889218767018dc4ca3f37d88915b6170ea24821bd6ef0c60912b6950\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/35/5057db0249224e9ab55a513fa6b79451473ceb7713017823c3\n",
            "Successfully built FastText\n",
            "Installing collected packages: pybind11, FastText\n",
            "Successfully installed FastText-0.9.3 pybind11-3.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install FastText"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step 1: installing the libraries\n",
        "import fasttext\n",
        "import os\n",
        "import joblib"
      ],
      "metadata": {
        "id": "Fz_Of8CN82x1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step 2: Creating Training Data\n",
        "def create_sample_data():\n",
        "  # sample sentences for training\n",
        "  sentences = [\n",
        "      \"The king rules the kingdom\",\n",
        "      \"The queen helps the king\",\n",
        "      \"Running is good for excercise\",\n",
        "      \"Walking is healthy activity\",\n",
        "      \"The walker walks slowly\",\n",
        "      \"Reading books is fun\",\n",
        "      \"The reader reads daily\"\n",
        "  ]\n",
        "\n",
        "  with open(\"training_data.txt\", \"w\") as f:\n",
        "    for sentence in sentences:\n",
        "      f.write(sentence.lower() + \"\\n\")\n",
        "\n",
        "  print(\"Training data created in 'training_data.txt'\")\n",
        "\n",
        "create_sample_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfs9SMy4EY-Z",
        "outputId": "7e422def-1472-43fa-c70d-8287430e1d2b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data created in 'training_data.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step 3: Training a basic fast text model\n",
        "def train_simple_model():\n",
        "  model = fasttext.train_unsupervised(\"training_data.txt\", model=\"skipgram\", dim=50, epoch=30, minCount=1, minn=3, maxn=6)\n",
        "  # training on the skipgram model\n",
        "  # choosing model as skipgram\n",
        "  # dimension choosen as 50\n",
        "  # epochs = 50\n",
        "  # min word frequency of embedding is choosen as 1\n",
        "  # minimum n gram is taken as 3\n",
        "  # maximum n gram is taken as 6\n",
        "\n",
        "  model.save_model(\"word_vectors.bin\")\n",
        "  print(\"Model trained and saved as 'word_vectors.bin'\")\n",
        "  return model\n",
        "\n",
        "train_simple_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZ9FtMyuHILX",
        "outputId": "ba0761fd-4b9d-4625-dc10-875aadbcd1bb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained and saved as 'word_vectors.bin'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fasttext.FastText._FastText at 0x7bbb4de77a10>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_simple_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TiwdLIfJiMm",
        "outputId": "f51965dd-f3d0-419e-aaf2-5adc069bf22c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained and saved as 'word_vectors.bin'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step 4: step getting word vecotrs\n",
        "def get_word_vectors(model):\n",
        "  king_vector = model.get_word_vector(\"king\")\n",
        "  print(f\"vector for 'king': {king_vector[:5]}\")\n",
        "  print(f\"vector shape: {king_vector.shape}\")\n",
        "\n",
        "  kingdom_vector = model.get_word_vector(\"kingdom\")\n",
        "  print(f\"vector for 'kingdom': {kingdom_vector[:5]}\")\n",
        "  print(f\"vector shape: {kingdom_vector.shape}\")\n",
        "\n",
        "get_word_vectors(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-Anm28LJu3a",
        "outputId": "eb088cf6-eaa1-4c11-81b3-66860f612564"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vector for 'king': [-0.00018306 -0.0003302   0.00042938  0.00089004 -0.00164623]\n",
            "vector shape: (50,)\n",
            "vector for 'kingdom': [-0.00059493  0.00241587 -0.00059253 -0.0007504  -0.0007329 ]\n",
            "vector shape: (50,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step 5: finding similar words\n",
        "def find_similar_words(model, word, k=3):\n",
        "  print(f\"\\n words similar to '{word}'\")\n",
        "  try:\n",
        "    neighbor_word = model.get_nearest_neighbors(word, k)\n",
        "    for i, (similarity, similar_words) in enumerate(neighbor_word):\n",
        "      print(f\"{i}. {similar_words} : {similarity}\")\n",
        "  except Exception as e:\n",
        "    print(f\"error: {e}\")\n",
        "find_similar_words(model, 'king')\n",
        "find_similar_words(model, \"kingdom\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnEbpNF0Ls1K",
        "outputId": "9758519d-7e4d-4cd6-fe55-12094b1095e2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " words similar to 'king'\n",
            "0. walks : 0.26921141147613525\n",
            "1. healthy : 0.23639050126075745\n",
            "2. rules : 0.23427143692970276\n",
            "\n",
            " words similar to 'kingdom'\n",
            "0. good : 0.23384441435337067\n",
            "1. rules : 0.22116202116012573\n",
            "2. is : 0.21689122915267944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # step 6 : text classification implementation\n",
        "# def create_classification_data():\n",
        "#   reviews=[\n",
        "#       (\"This movie is amazing and fun\", ),\n",
        "#       (),\n",
        "#       (),\n",
        "#   ]"
      ],
      "metadata": {
        "id": "NbUhcrcnNdBQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}