{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-ZeMGiUFne_",
        "outputId": "b1deaaea-c069-428a-fcb0-0b4530a2572e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ],
      "source": [
        "! pip install gensim\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "ZoPrxsoyHEZj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4ua2VhaJIvP",
        "outputId": "cc3dc587-8862-4303-b482-2ba60e58dcff"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    \"This is the first document\",\n",
        "    \"This is the second document\",\n",
        "    \"This is the third document\",\n",
        "    \"This is the fourth document\"\n",
        "]"
      ],
      "metadata": {
        "id": "k1Ok8AwrGL2W"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the documents, and create Tagged Documents\n",
        "tagged_data = [TaggedDocument(words=word_tokenize(doc.lower()), tags=[str(i)]) for i, doc in enumerate(data)]\n",
        "print(tagged_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRtCqfLdH4Ij",
        "outputId": "0d4c5e6d-e44f-42d0-b6ed-aa2326777756"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TaggedDocument(words=['this', 'is', 'the', 'first', 'document'], tags=['0']), TaggedDocument(words=['this', 'is', 'the', 'second', 'document'], tags=['1']), TaggedDocument(words=['this', 'is', 'the', 'third', 'document'], tags=['2']), TaggedDocument(words=['this', 'is', 'the', 'fourth', 'document'], tags=['3'])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=100)  # you can limit vocab size"
      ],
      "metadata": {
        "id": "1w9DwcsZUBRT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_data = []\n",
        "for i, doc in enumerate(data):\n",
        "  tag_docs = TaggedDocument(words = word_tokenize(doc.lower()), tags=[str(i)])\n",
        "  tagged_data.append(tag_docs)\n",
        "\n",
        "print(tagged_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVHDPTeZNEa0",
        "outputId": "617e9cf3-59ca-45ba-d655-aa9f859415d8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TaggedDocument(words=['this', 'is', 'the', 'first', 'document'], tags=['0']), TaggedDocument(words=['this', 'is', 'the', 'second', 'document'], tags=['1']), TaggedDocument(words=['this', 'is', 'the', 'third', 'document'], tags=['2']), TaggedDocument(words=['this', 'is', 'the', 'fourth', 'document'], tags=['3'])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the doc2vec model\n",
        "model = Doc2Vec(vector_size=20, min_count=2, epochs=50)\n",
        "model.build_vocab(tagged_data)\n",
        "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)"
      ],
      "metadata": {
        "id": "_rNyi_adH9pb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the doc2vec model\n",
        "model = Doc2Vec(vector_size = 20, min_count=2, epochs=50)\n",
        "model.build_vocab(tagged_data)\n",
        "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)"
      ],
      "metadata": {
        "id": "2ITXM1prVQAa"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the document vectors\n",
        "document_vectors = [model.infer_vector(word_tokenize(doc.lower())) for doc in data]\n"
      ],
      "metadata": {
        "id": "0dsuMJKIKGWa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the document vectors\n",
        "document_vectors = []\n",
        "for doc in data:\n",
        "  vec = model.infer_vector(word_tokenize(doc.lower()))\n",
        "  document_vectors.append(vec)\n",
        "\n",
        "print(document_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JbAa0AoWN5x",
        "outputId": "92127867-5bdd-4b02-ee48-2452a0032f1c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([ 0.01914601,  0.01581868,  0.01517364,  0.01450728, -0.01254469,\n",
            "        0.02134449, -0.02158963, -0.00790595, -0.02162696,  0.01948986,\n",
            "       -0.00524412, -0.02197738,  0.0078729 ,  0.01225551,  0.01517913,\n",
            "       -0.02130485, -0.00079446, -0.02119508,  0.02412067,  0.01603048],\n",
            "      dtype=float32), array([ 0.01655311, -0.01528235, -0.00576514,  0.00123265, -0.00248322,\n",
            "       -0.00954959, -0.00020489,  0.00905933,  0.00537069,  0.02177139,\n",
            "       -0.01555459,  0.02197477,  0.01155983, -0.00930728,  0.0017278 ,\n",
            "       -0.00097345,  0.01894876, -0.01965865, -0.02363788,  0.00099795],\n",
            "      dtype=float32), array([-0.02170233, -0.00900744, -0.00751184, -0.01114856, -0.00073212,\n",
            "       -0.01919173,  0.01692825,  0.00668934, -0.00966807,  0.01537576,\n",
            "        0.0131486 ,  0.00748374,  0.01138197,  0.00705871, -0.01292038,\n",
            "       -0.00396556,  0.01600288,  0.02036013,  0.01436794,  0.01962908],\n",
            "      dtype=float32), array([ 0.02109862,  0.01905306, -0.00967325, -0.01916632,  0.00881103,\n",
            "       -0.00624941,  0.01118639,  0.00603689,  0.00408432, -0.02142596,\n",
            "       -0.00143453, -0.02380223,  0.01501877, -0.01376261, -0.01487743,\n",
            "       -0.02237146,  0.0216693 ,  0.01047956, -0.00734694, -0.01283192],\n",
            "      dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print the document vectors\n",
        "for i, doc in enumerate(data):\n",
        "  print(\"document: \", i+1, \" : \", doc)\n",
        "  print(\"vector: \", document_vectors[i])\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIXuxcX4KUgl",
        "outputId": "60b03742-795f-47f2-bf9e-b0adf9bb9fca"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "document:  1  :  This is the first document\n",
            "vector:  [ 0.01914601  0.01581868  0.01517364  0.01450728 -0.01254469  0.02134449\n",
            " -0.02158963 -0.00790595 -0.02162696  0.01948986 -0.00524412 -0.02197738\n",
            "  0.0078729   0.01225551  0.01517913 -0.02130485 -0.00079446 -0.02119508\n",
            "  0.02412067  0.01603048]\n",
            "\n",
            "document:  2  :  This is the second document\n",
            "vector:  [ 0.01655311 -0.01528235 -0.00576514  0.00123265 -0.00248322 -0.00954959\n",
            " -0.00020489  0.00905933  0.00537069  0.02177139 -0.01555459  0.02197477\n",
            "  0.01155983 -0.00930728  0.0017278  -0.00097345  0.01894876 -0.01965865\n",
            " -0.02363788  0.00099795]\n",
            "\n",
            "document:  3  :  This is the third document\n",
            "vector:  [-0.02170233 -0.00900744 -0.00751184 -0.01114856 -0.00073212 -0.01919173\n",
            "  0.01692825  0.00668934 -0.00966807  0.01537576  0.0131486   0.00748374\n",
            "  0.01138197  0.00705871 -0.01292038 -0.00396556  0.01600288  0.02036013\n",
            "  0.01436794  0.01962908]\n",
            "\n",
            "document:  4  :  This is the fourth document\n",
            "vector:  [ 0.02109862  0.01905306 -0.00967325 -0.01916632  0.00881103 -0.00624941\n",
            "  0.01118639  0.00603689  0.00408432 -0.02142596 -0.00143453 -0.02380223\n",
            "  0.01501877 -0.01376261 -0.01487743 -0.02237146  0.0216693   0.01047956\n",
            " -0.00734694 -0.01283192]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MMbvIfRFKXLu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}